"""
Asynchronous message processor for WhatsApp.
Removed Celery for single-container architecture using BackgroundTasks.
"""
import asyncio
import logging
import re
import os
from src.config import settings
from src.services.green_api import green_api
from src.services.llm import llm_service
from src.services.stt import get_stt_provider
from src.services.context import context_service
from src.handlers import (
    handle_text_message,
    handle_extended_text_message,
    handle_quoted_message,
    handle_audio_message,
    handle_image_message,
    handle_button_response,
)

logging.basicConfig(level=settings.LOG_LEVEL)
logger = logging.getLogger(__name__)

async def process_message(event_data: dict):
    """Entry point for background processing."""
    try:
        await _process_message_async(event_data)
    except Exception as e:
        logger.error(f"Processing Failed: {e}")


async def _process_message_async(event_data: dict):
    """Main message processing logic."""
    logger.info(f"Processing event: {event_data}")
    
    # Validate event type
    if event_data.get("typeWebhook") != "incomingMessageReceived":
        return
    
    # Extract sender info
    sender_data = event_data.get("senderData", {})
    chat_id = sender_data.get("chatId")
    sender_id = sender_data.get("sender", chat_id)
    sender_name = sender_data.get("senderName", "User")
    message_data = event_data.get("messageData", {})
    message_type = message_data.get("typeMessage")
    
    # Check blacklist
    if await context_service.is_blacklisted(sender_id):
        logger.info(f"Blocked message from blacklisted user: {sender_id}")
        return
    
    # Process message by type
    text_content = ""
    quoted_context = None
    structured_content = None
    file_path = None
    has_media = False
    
    if message_type == "textMessage":
        text_content, _ = await handle_text_message(message_data)
        
    elif message_type == "extendedTextMessage":
        text_content, quoted_context = await handle_extended_text_message(message_data, chat_id)
        
    elif message_type == "quotedMessage":
        text_content, quoted_context = await handle_quoted_message(message_data, chat_id)
        
    elif message_type in ["audioMessage", "voiceMessage"]:
        text_content, should_skip = await handle_audio_message(message_data, chat_id)
        if should_skip:
            return
            
    elif message_type == "imageMessage":
        text_content, structured_content, file_path = await handle_image_message(message_data, chat_id)
        has_media = structured_content is not None
    
    elif message_type == "buttonsResponseMessage":
        # Handle button clicks
        button_text, button_id = await handle_button_response(message_data)
        if button_id:
            # Process button action based on ID
            await _handle_button_action(chat_id, button_id, button_text)
            return
    
    if not text_content:
        return
    
    # Check if group chat
    is_group = chat_id.endswith("@g.us")
    
    # Handle commands
    command_result = await _handle_commands(
        text_content, chat_id, sender_id, is_group
    )
    if command_result:
        return
    
    # Store group message for summarization
    if is_group:
        content_to_store = text_content
        if message_type in ["audioMessage", "voiceMessage"] and "Ğ¢ĞµĞºÑÑ‚:" in text_content:
            content_to_store = text_content.split("Ğ¢ĞµĞºÑÑ‚:")[-1].strip()
        await context_service.add_group_message(chat_id, sender_name, content_to_store)
    
    # Check if should reply in group
    if is_group and not await _should_reply_in_group(chat_id, text_content):
        return
    
    # Prepare LLM request
    history = await context_service.get_history(chat_id)
    llm_messages = [{"role": msg["role"], "content": msg["content"]} for msg in history]
    
    current_content = structured_content if has_media else text_content
    
    # Add quoted context if present
    if quoted_context:
        if isinstance(current_content, str):
            current_content = f"{quoted_context}\n\nĞ’Ğ¾Ğ¿Ñ€Ğ¾Ñ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ñ: {current_content}"
        elif isinstance(current_content, dict):
            current_content["text"] = f"{quoted_context}\n\nĞ’Ğ¾Ğ¿Ñ€Ğ¾Ñ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ñ: {current_content.get('text', '')}"
    
    llm_messages.append({"role": "user", "content": current_content})
    
    # Get LLM response
    try:
        response_text = await llm_service.get_response(llm_messages)
    except Exception as e:
        logger.error(f"LLM service error for chat {chat_id}: {e}")
        await green_api.send_message(chat_id, "âŒ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ñ€Ğ¸ Ğ¿Ğ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ğ¸ Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ° Ğ¾Ñ‚ AI. ĞŸĞ¾Ğ¿Ñ€Ğ¾Ğ±ÑƒĞ¹Ñ‚Ğµ Ğ¿Ğ¾Ğ·Ğ¶Ğµ.")
        return

    # Check if response is valid
    if not response_text or "ĞÑˆĞ¸Ğ±ĞºĞ°" in response_text:
        logger.warning(f"Invalid LLM response for chat {chat_id}: {response_text}")

    # Update history
    try:
        # User message was already added for groups at line 106
        if not is_group:
            await context_service.add_message(chat_id, "user", text_content)
        
        await context_service.add_message(chat_id, "assistant", response_text)
    except Exception as e:
        logger.error(f"Failed to save history for chat {chat_id}: {e}")

    # Send response
    send_result = await green_api.send_message(chat_id, response_text)
    if not send_result:
        logger.error(f"Failed to send message to chat {chat_id}")

    # Cleanup media
    if has_media and file_path and os.path.exists(file_path):
        try:
            os.remove(file_path)
        except Exception as e:
            logger.warning(f"Failed to cleanup media file {file_path}: {e}")


async def _should_reply_in_group(chat_id: str, text: str) -> bool:
    """Check if bot should reply in group chat."""
    is_enabled = await context_service.is_ai_enabled(chat_id)
    
    msg_lower = text.lower()
    bot_nickname = settings.BOT_NICKNAME.lower()
    
    # Match exact word
    pattern = rf'\b{re.escape(bot_nickname)}\b'
    is_triggered = bool(re.search(pattern, msg_lower))
    
    # Check if message starts with nickname
    if not is_triggered:
        is_triggered = msg_lower.startswith(f"{bot_nickname} ") or msg_lower.startswith(f"{bot_nickname},")
    
    return is_enabled or is_triggered


async def _handle_button_action(chat_id: str, button_id: str, button_text: str):
    """
    Handle interactive button action based on button ID.
    Add custom button handlers here.
    """
    # Built-in button actions
    if button_id == "btn_reset":
        await context_service.clear_history(chat_id)
        await green_api.send_message(chat_id, "ğŸ”„ ĞŸĞ°Ğ¼ÑÑ‚ÑŒ ÑĞ±Ñ€Ğ¾ÑˆĞµĞ½Ğ°!")
        return
    
    elif button_id == "btn_help":
        await _send_help_with_buttons(chat_id)
        return
    
    elif button_id == "btn_transcribe":
        current = await context_service.get_transcribe_mode(chat_id)
        await context_service.set_transcribe_mode(chat_id, not current)
        msg = "ğŸ™ï¸ Ğ¢Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ±Ğ°Ñ†Ğ¸Ñ Ğ’ĞšĞ›" if not current else "ğŸ¤– Ğ¢Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ±Ğ°Ñ†Ğ¸Ñ Ğ’Ğ«ĞšĞ›"
        await green_api.send_message(chat_id, msg)
        return
    
    elif button_id == "btn_ai_on":
        await context_service.set_ai_enabled(chat_id, True)
        await green_api.send_message(chat_id, "ğŸ¤– AI Ğ²ĞºĞ»ÑÑ‡ĞµĞ½")
        return
    
    elif button_id == "btn_ai_off":
        await context_service.set_ai_enabled(chat_id, False)
        await green_api.send_message(chat_id, "ğŸ˜´ AI Ğ²Ñ‹ĞºĞ»ÑÑ‡ĞµĞ½")
        return
    
    # Custom button: treat as message
    logger.info(f"Unknown button action: {button_id}")
    # Could process button_text as a message here if needed


async def _handle_commands(text: str, chat_id: str, sender_id: str, is_group: bool) -> bool:
    """
    Handle slash commands.
    Returns True if command was handled and processing should stop.
    """
    cmd = text.strip().lower()
    
    # /ai on|off
    if cmd == "/ai on":
        await context_service.set_ai_enabled(chat_id, True)
        await green_api.send_message(chat_id, "ğŸ¤– ĞĞ²Ñ‚Ğ¾Ğ¾Ñ‚Ğ²ĞµÑ‚Ñ‹ Ğ²ĞºĞ»ÑÑ‡ĞµĞ½Ñ‹.")
        return True
    elif cmd == "/ai off":
        await context_service.set_ai_enabled(chat_id, False)
        await green_api.send_message(chat_id, "ğŸ˜´ ĞĞ²Ñ‚Ğ¾Ğ¾Ñ‚Ğ²ĞµÑ‚Ñ‹ Ğ²Ñ‹ĞºĞ»ÑÑ‡ĞµĞ½Ñ‹.")
        return True
    
    # /reset
    if cmd == "/reset":
        await context_service.clear_history(chat_id)
        await context_service.clear_group_messages(chat_id)
        await green_api.send_message(chat_id, "ğŸ”„ ĞšĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚ ÑĞ±Ñ€Ğ¾ÑˆĞµĞ½.")
        return True
    
    # /help
    if cmd == "/help":
        help_text = f"""ğŸ“š *ĞšĞ¾Ğ¼Ğ°Ğ½Ğ´Ñ‹ Ğ±Ğ¾Ñ‚Ğ°:*

ğŸ”„ /reset - ÑĞ±Ñ€Ğ¾ÑĞ¸Ñ‚ÑŒ Ğ¿Ğ°Ğ¼ÑÑ‚ÑŒ
ğŸ¤– /ai on|off - Ğ°Ğ²Ñ‚Ğ¾Ğ¾Ñ‚Ğ²ĞµÑ‚Ñ‹ Ğ² Ğ³Ñ€ÑƒĞ¿Ğ¿Ğµ
ğŸ“‹ /summary - Ñ€ĞµĞ·ÑĞ¼Ğµ Ñ‡Ğ°Ñ‚Ğ°
ğŸ™ï¸ /transcribe - Ñ‚Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ±Ğ°Ñ†Ğ¸Ñ
ğŸ“Š /stats - ÑÑ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ°

ğŸ” /search - Ğ¿Ğ¾Ğ¸ÑĞº Ñ AI-Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ¾Ğ¼
ğŸ¨ /draw - Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ ĞºĞ°Ñ€Ñ‚Ğ¸Ğ½Ğ¾Ğº

ğŸ’¡ ĞĞ¸Ğº: *{settings.BOT_NICKNAME}*"""
        await green_api.send_message(chat_id, help_text)
        return True
    
    # /transcribe
    if cmd == "/transcribe":
        current = await context_service.get_transcribe_mode(chat_id)
        await context_service.set_transcribe_mode(chat_id, not current)
        msg = "ğŸ™ï¸ Ğ ĞµĞ¶Ğ¸Ğ¼ Ñ‚Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ±Ğ°Ñ†Ğ¸Ğ¸ Ğ’ĞšĞ›" if not current else "ğŸ¤– Ğ ĞµĞ¶Ğ¸Ğ¼ Ñ‚Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ±Ğ°Ñ†Ğ¸Ğ¸ Ğ’Ğ«ĞšĞ›"
        await green_api.send_message(chat_id, msg)
        return True
    
    # /stats
    if cmd == "/stats":
        history = await context_service.get_history(chat_id)
        stats = f"""ğŸ“Š *Ğ¡Ñ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ°:*

ğŸ’¬ Ğ¡Ğ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğ¹ Ğ² Ğ¿Ğ°Ğ¼ÑÑ‚Ğ¸: {len(history)}
ğŸ¤– ĞĞ¸Ğº: {settings.BOT_NICKNAME}"""
        await green_api.send_message(chat_id, stats)
        return True
    

    
    # /search - web search with AI summarization (Perplexity-style)
    if cmd.startswith("/search ") or cmd == "/search":
        parts = text.strip().split(maxsplit=1)
        if len(parts) < 2:
            await green_api.send_message(
                chat_id, 
                "ğŸ” *ĞŸĞ¾Ğ¸ÑĞº Ğ² Ğ¸Ğ½Ñ‚ĞµÑ€Ğ½ĞµÑ‚Ğµ*\n\n"
                "Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ: /search <Ğ·Ğ°Ğ¿Ñ€Ğ¾Ñ>\n"
                "ĞŸÑ€Ğ¸Ğ¼ĞµÑ€: /search Ğ¿Ğ¾Ğ³Ğ¾Ğ´Ğ° ĞĞ»Ğ¼Ğ°Ñ‚Ñ‹\n\n"
                "ğŸ’¡ AI Ğ¿Ñ€Ğ¾Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞµÑ‚ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ğ¸ Ğ´Ğ°ÑÑ‚ Ğ¾Ñ‚Ğ²ĞµÑ‚ Ñ Ğ¸ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸ĞºĞ°Ğ¼Ğ¸"
            )
            return True
        
        query = parts[1]
        await green_api.send_message(chat_id, f"ğŸ” Ğ˜Ñ‰Ñƒ: _{query}_\nâ³ ĞĞ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒÑ Ğ¸ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸ĞºĞ¸...")
        
        from src.services.search import search_and_summarize
        result = await search_and_summarize(query)
        await green_api.send_message(chat_id, result)
        return True
    
    # /draw - image generation with Pollinations.ai
    if cmd.startswith("/draw ") or cmd == "/draw":
        parts = text.strip().split(maxsplit=1)
        if len(parts) < 2:
            await green_api.send_message(chat_id, "ğŸ¨ *Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹*\n\nĞ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ: /draw <Ğ¾Ğ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğµ>\nĞŸÑ€Ğ¸Ğ¼ĞµÑ€: /draw ĞºĞ¾Ñ‚ Ğ² ĞºĞ¾ÑĞ¼Ğ¾ÑĞµ\n\nğŸ’¡ ĞŸÑ€Ğ¾Ğ¼Ğ¿Ñ‚ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸ ÑƒĞ»ÑƒÑ‡ÑˆĞ°ĞµÑ‚ÑÑ AI")
            return True
        
        prompt = parts[1]
        await green_api.send_message(chat_id, f"ğŸ¨ Ğ“ĞµĞ½ĞµÑ€Ğ¸Ñ€ÑƒÑ: _{prompt}_\nâ³ Ğ£Ğ»ÑƒÑ‡ÑˆĞ°Ñ Ğ¿Ñ€Ğ¾Ğ¼Ğ¿Ñ‚ Ğ¸ ÑĞ¾Ğ·Ğ´Ğ°Ñ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğµ...")
        
        from src.services.image_gen import generate_image
        
        # Generate image with prompt enhancement
        file_path, enhanced_prompt, seed = await generate_image(prompt)
        
        if file_path and os.path.exists(file_path):
            # Create caption with original and enhanced prompt
            prompt_preview = enhanced_prompt[:150] + '...' if len(enhanced_prompt) > 150 else enhanced_prompt
            caption = f"ğŸ¨ *{prompt}*\n\nâœ¨ _{prompt_preview}_"
            if seed:
                caption += f"\n\nğŸŒ± Seed: {seed}"
            
            # Upload to WhatsApp using SendFileByUpload
            result = await green_api.send_file_by_upload(
                chat_id=chat_id,
                file_path=file_path,
                caption=caption,
                file_name=f"art_{seed}.png"
            )
            
            # Cleanup local file
            try:
                os.remove(file_path)
                logger.info(f"Cleaned up: {file_path}")
            except Exception as e:
                logger.warning(f"Failed to cleanup: {e}")
            
            if not result:
                await green_api.send_message(chat_id, "âŒ ĞĞµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ Ğ¾Ñ‚Ğ¿Ñ€Ğ°Ğ²Ğ¸Ñ‚ÑŒ ĞºĞ°Ñ€Ñ‚Ğ¸Ğ½ĞºÑƒ. ĞŸĞ¾Ğ¿Ñ€Ğ¾Ğ±ÑƒĞ¹Ñ‚Ğµ ĞµÑ‰Ñ‘ Ñ€Ğ°Ğ·.")
        else:
            await green_api.send_message(chat_id, "âŒ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸.\n\nğŸ’¡ ĞŸĞ¾Ğ¿Ñ€Ğ¾Ğ±ÑƒĞ¹Ñ‚Ğµ:\nâ€¢ Ğ”Ñ€ÑƒĞ³Ğ¾Ğ¹ Ğ¿Ñ€Ğ¾Ğ¼Ğ¿Ñ‚\nâ€¢ Ğ‘Ğ¾Ğ»ĞµĞµ Ğ¿Ñ€Ğ¾ÑÑ‚Ğ¾Ğµ Ğ¾Ğ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğµ\nâ€¢ ĞĞ½Ğ³Ğ»Ğ¸Ğ¹ÑĞºĞ¸Ğ¹ ÑĞ·Ñ‹Ğº")
        
        return True
    
    # /summary (groups only)
    if cmd == "/summary":
        if not is_group:
            await green_api.send_message(chat_id, "ĞšĞ¾Ğ¼Ğ°Ğ½Ğ´Ğ° Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ğ° Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ² Ğ³Ñ€ÑƒĞ¿Ğ¿Ğ°Ñ….")
            return True
        await _handle_summary_command(chat_id)
        return True
    
    # Admin commands
    if settings.ADMIN_CHAT_ID and sender_id == settings.ADMIN_CHAT_ID:
        if text.strip().startswith("/ban "):
            target = text.strip()[5:].strip()
            if target:
                await context_service.add_to_blacklist(target)
                await green_api.send_message(chat_id, f"ğŸš« {target} Ğ·Ğ°Ğ±Ğ»Ğ¾ĞºĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½")
            return True
        
        if text.strip().startswith("/unban "):
            target = text.strip()[7:].strip()
            if target:
                await context_service.remove_from_blacklist(target)
                await green_api.send_message(chat_id, f"âœ… {target} Ñ€Ğ°Ğ·Ğ±Ğ»Ğ¾ĞºĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½")
            return True
        
        if cmd == "/blacklist":
            bl = await context_service.get_blacklist()
            if bl:
                await green_api.send_message(chat_id, "ğŸš« Blacklist:\n" + "\n".join(f"â€¢ {u}" for u in bl))
            else:
                await green_api.send_message(chat_id, "Blacklist Ğ¿ÑƒÑÑ‚")
            return True
    
    return False


async def _handle_summary_command(chat_id: str):
    """Handle /summary command for group chats."""
    await green_api.send_message(chat_id, "â³ Ğ¡Ğ¾Ğ±Ğ¸Ñ€Ğ°Ñ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ñ...")
    
    raw_messages = await green_api.get_chat_history(chat_id, settings.SUMMARY_MESSAGE_COUNT)
    if not raw_messages:
        await green_api.send_message(chat_id, "ĞĞµÑ‚ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğ¹ Ğ´Ğ»Ñ ÑÑƒĞ¼Ğ¼Ğ°Ñ€Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸.")
        return
    
    formatted_messages = []
    stt = get_stt_provider()
    audio_count = 0
    
    for msg in reversed(raw_messages):
        msg_type = msg.get("typeMessage", "")
        sender = msg.get("senderName", "?")
        if msg.get("type") == "outgoing":
            sender = "Ğ‘Ğ¾Ñ‚"
        
        content = None
        
        if msg_type == "textMessage":
            content = msg.get("textMessage", "")
        elif msg_type == "extendedTextMessage":
            content = msg.get("extendedTextMessage", {}).get("text", "")
        elif msg_type in ["audioMessage", "voiceMessage"]:
            download_url = msg.get("downloadUrl", "")
            if download_url:
                try:
                    file_path = os.path.join(settings.MEDIA_DIR, f"sum_{msg.get('idMessage', 'tmp')}.ogg")
                    await green_api.download_file(download_url, file_path)
                    transcription = await stt.transcribe(file_path)
                    if os.path.exists(file_path):
                        os.remove(file_path)
                    if transcription:
                        content = f"[ğŸ™ï¸]: {transcription}"
                        audio_count += 1
                except Exception as e:
                    logger.error(f"Summary audio transcription failed: {e}")
                    content = "[ğŸ™ï¸]"
            else:
                content = "[ğŸ™ï¸]"
        elif msg_type == "imageMessage":
            content = f"[ğŸ“·] {msg.get('caption', '')}"
        
        if content:
            formatted_messages.append(f"{sender}: {content}")
    
    if not formatted_messages:
        await green_api.send_message(chat_id, "ĞĞµÑ‚ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğ¹ Ğ´Ğ»Ñ ÑÑƒĞ¼Ğ¼Ğ°Ñ€Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸.")
        return
    
    # Limit total text to avoid token limit issues
    # ~4 chars per token, Groq limit is 6000 tokens, we want ~4000 chars max for content
    MAX_CONTENT_CHARS = 4000
    messages_text = "\n".join(formatted_messages)
    if len(messages_text) > MAX_CONTENT_CHARS:
        # Truncate from the beginning (keep recent messages)
        messages_text = "...[Ğ¾Ğ±Ñ€ĞµĞ·Ğ°Ğ½Ğ¾]...\n" + messages_text[-MAX_CONTENT_CHARS:]
    
    summary = await llm_service.get_response([{"role": "user", "content": prompt}])
    
    note = f" (ğŸ™ï¸ {audio_count})" if audio_count else ""
    await green_api.send_message(chat_id, f"ğŸ“‹ *Ğ ĞµĞ·ÑĞ¼Ğµ* ({len(formatted_messages)} ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğ¹{note}):\n\n{summary}")
